{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb1689b",
   "metadata": {},
   "source": [
    "## Tuning features towards simple language\n",
    "In this notebook we show an effort to modify a common way of extracting features in an attempt to improve\n",
    "the performance when classifying simple language.\n",
    "We first set up the feature extraction, and then run two experiments.\n",
    "Our feature is a modified version of tf-idf, where before applying the vectorizer,\n",
    "we drop all tokens that arent nouns, verbs or adjectives. We also include the lemmas\n",
    "instead of the tokens themselves.\n",
    "\n",
    "We then train and test a classifier using tf-idf vectors with the out of the box vectorizer,\n",
    "using simple language once, and conventional language in a separate trial.\n",
    "We then train and test for both cases again, using our modified features.\n",
    "\n",
    "If our approach is successful, the modified feature won't improve the classification of the\n",
    "conventional language by a lot, if at all, but will improve the classification of simple language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d326ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937e011",
   "metadata": {},
   "source": [
    "We are using the TfIdf vectorizer from scikit learn, both for the control and internally in our modified feature.\n",
    "An attempt had been made to implement the tf-idf computation manually, but we ran into the issue of the resulting\n",
    "vectors dimensionality, therefore we resorted to the premade system.\n",
    "We also include spacy and its pretrained language model for lemmatization and POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c18c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using spacys pretrained model to obtain pos tags for our data, and to lemmatize it\n",
    "nlp = spacy.load(\"de_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df133192",
   "metadata": {},
   "source": [
    "This notebook requires the cleaned data from the cleaning and metadata notebook written by me to be in the same directory, so they can be read here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fb65083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.read_csv(\"clean_leichte_sprache.csv\")\n",
    "df_poli = pd.read_csv(\"clean_politik_normal.csv\")\n",
    "df_cult = pd.read_csv(\"clean_kultur_normal.csv\")\n",
    "df_sport = pd.read_csv(\"clean_sport_normal.csv\")\n",
    "df_normal = pd.concat([df_poli, df_cult, df_sport])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319a231",
   "metadata": {},
   "source": [
    "We define our modified feature, with one fit_transform which calls the fit_transform of the Tf-Idf vectorizer,\n",
    "and one standard transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cf14b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_featurizer(series_in) :\n",
    "    # our very first step is to throw out all words that dont have one of the following\n",
    "    # pos tags\n",
    "    wanted_tags = [\"ADJ\", \"ADV\", \"NOUN\", \"PROPN\", \"VERB\"]\n",
    "    \n",
    "    #for saving the augmented documents\n",
    "    stripped_documents = []\n",
    "    \n",
    "    for document in series_in :\n",
    "        stripped_document = \"\"\n",
    "        \n",
    "        doc = nlp(document)\n",
    "        for token in doc :\n",
    "            if token.pos_ in wanted_tags :\n",
    "                stripped_document +=token.lemma_ + \" \" # we lemmatize the words for less variety, speeding up the computation\n",
    "        stripped_documents.append(stripped_document)\n",
    "        # now we only have the lemmas of the desired pos tags, and have already greatly reduced our amount of words.     \n",
    "    \n",
    "    return stripped_documents\n",
    "\n",
    "def fit_transform(series_in, vectorizer) :\n",
    "    stripped_documents = custom_featurizer(series_in)\n",
    "    tf_idf_vectors = vectorizer.fit_transform(stripped_documents)\n",
    "    \n",
    "    return tf_idf_vectors.toarray()\n",
    "\n",
    "def transform(series_in, vectorizer) :\n",
    "    stripped_documents = custom_featurizer(series_in)\n",
    "    tf_idf_vectors = vectorizer.transform(stripped_documents)\n",
    "    \n",
    "    return tf_idf_vectors.toarray()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d2167",
   "metadata": {},
   "source": [
    "We are using the standard train test splitting, and for the classifier we are using a multilayer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19214105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ee70c",
   "metadata": {},
   "source": [
    "First our control. We split for train and test, using a 70-30 split. We then vectorize using the standard tf-idf\n",
    "vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(train_data, test_data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # fit on train data + transform\n",
    "    train_tfidf = vectorizer.fit_transform(train_data).toarray()\n",
    "    # transform test data\n",
    "    test_tfidf = vectorizer.transform(test_data).toarray() \n",
    "    return train_tfidf, test_tfidf\n",
    "\n",
    "# train test split and vectorize simple texts\n",
    "train_text_simple, test_text_simple, train_label_simple, test_label_simple = train_test_split(df_simple[\"text\"], df_simple[\"label\"], train_size=0.7, random_state=0)\n",
    "train_vec_simple, test_vec_simple = vectorize(train_text_simple, test_text_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b454b8",
   "metadata": {},
   "source": [
    "Now we can train and test our classifier, and show our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c17d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP classifier with simple\n",
    "clf_simple = MLPClassifier()\n",
    "clf_simple.fit(train_vec_simple, train_label_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels and evaluate the results for simple language\n",
    "predictions_simple = clf_simple.predict(test_vec_simple)\n",
    "print(classification_report(test_label_simple, predictions_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69b63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(train_data, test_data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # fit on train data + transform\n",
    "    train_tfidf = vectorizer.fit_transform(train_data).toarray()\n",
    "    # transform test data\n",
    "    test_tfidf = vectorizer.transform(test_data).toarray() \n",
    "    return train_tfidf, test_tfidf\n",
    "\n",
    "# train test split and vectorize normal texts\n",
    "train_text_normal, test_text_normal, train_label_normal, test_label_normal = train_test_split(df_normal[\"text\"], df_normal[\"label\"], train_size=0.7, random_state=0)\n",
    "train_vec_normal, test_vec_normal = vectorize(train_text_normal, test_text_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c84f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_normal = MLPClassifier()\n",
    "clf_normal.fit(train_vec_normal, train_label_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da74d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Kultur       0.96      0.96      0.96       704\n",
      " Nachrichten       0.95      0.96      0.96       673\n",
      "       Sport       0.99      0.99      0.99       798\n",
      "\n",
      "    accuracy                           0.97      2175\n",
      "   macro avg       0.97      0.97      0.97      2175\n",
      "weighted avg       0.97      0.97      0.97      2175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the labels and evaluate the results for normal language\n",
    "predictions_normal = clf_normal.predict(test_vec_normal)\n",
    "print(classification_report(test_label_normal, predictions_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42fcc3",
   "metadata": {},
   "source": [
    "Now we can do the same setup, but with our modified features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74bce097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(train_data, test_data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # fit on train data + transform\n",
    "    train_modified = fit_transform(train_data, vectorizer)\n",
    "    # transform test data\n",
    "    test_modified = transform(test_data, vectorizer) \n",
    "    return train_modified, test_modified\n",
    "\n",
    "# train test split and vectorize simple texts\n",
    "train_text_simple, test_text_simple, train_label_simple, test_label_simple = train_test_split(df_simple[\"text\"], df_simple[\"label\"], train_size=0.7, random_state=0)\n",
    "train_vec_simple, test_vec_simple = vectorize(train_text_simple, test_text_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8deb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4032    Wichtiger Jahres-Tag Deutschland und das Land ...\n",
       "2976    Neue Regierung in Italien Italien hat eine neu...\n",
       "461     Thomas-Mann-Haus  Thomas Mann war ein berühmte...\n",
       "3565    Naher Osten Der Präsident von dem Land USA hei...\n",
       "1767    Chris Froome gewinnt Der Rad-Fahrer Christophe...\n",
       "                              ...                        \n",
       "1033    Ausstellung über Deutschland In einem Museum i...\n",
       "3264    Urteil erwartet Ein Gericht in München will sc...\n",
       "1653    Champions League: Achtel-Finale In der Fußball...\n",
       "2607    Neuer US-Präsident im Amt Der Demokrat Joe Bid...\n",
       "2732    USA ziehen mehr Soldaten ab Das Land USA will ...\n",
       "Name: text, Length: 3187, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30853e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train MLP classifier with simple\n",
    "clf_simple = MLPClassifier()\n",
    "clf_simple.fit(train_vec_simple, train_label_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65588444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Kultur       0.93      0.91      0.92       397\n",
      " Nachrichten       0.93      0.95      0.94       595\n",
      "       Sport       0.99      0.98      0.99       375\n",
      "\n",
      "    accuracy                           0.95      1367\n",
      "   macro avg       0.95      0.95      0.95      1367\n",
      "weighted avg       0.95      0.95      0.95      1367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the labels and evaluate the results for simple language\n",
    "predictions_simple = clf_simple.predict(test_vec_simple)\n",
    "print(classification_report(test_label_simple, predictions_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7fd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(train_data, test_data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # fit on train data + transform\n",
    "    train_modified = fit_transform(train_data, vectorizer)\n",
    "    # transform test data\n",
    "    test_modified = transform(test_data, vectorizer)\n",
    "    return train_modified, test_modified\n",
    "\n",
    "# train test split and vectorize normal texts\n",
    "train_text_normal, test_text_normal, train_label_normal, test_label_normal = train_test_split(df_normal[\"text\"], df_normal[\"label\"], train_size=0.7, random_state=0)\n",
    "train_vec_normal, test_vec_normal = vectorize(train_text_normal, test_text_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a57e604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_normal = MLPClassifier()\n",
    "clf_normal.fit(train_vec_normal, train_label_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "540e44eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Kultur       0.95      0.96      0.96       704\n",
      " Nachrichten       0.96      0.96      0.96       673\n",
      "       Sport       0.99      0.99      0.99       798\n",
      "\n",
      "    accuracy                           0.97      2175\n",
      "   macro avg       0.97      0.97      0.97      2175\n",
      "weighted avg       0.97      0.97      0.97      2175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the labels and evaluate the results for normal language\n",
    "predictions_normal = clf_normal.predict(test_vec_normal)\n",
    "print(classification_report(test_label_normal, predictions_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e541d2",
   "metadata": {},
   "source": [
    "Author: Henri Thölke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d4f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
