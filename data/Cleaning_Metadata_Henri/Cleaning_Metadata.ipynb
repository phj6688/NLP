{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01616607",
   "metadata": {},
   "source": [
    "# Datacleaning and metadata generation\n",
    "\n",
    "This notebook contains a script to clean and process our simple language dataset, in order to\n",
    "do some minor analysis and gather some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "074c12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f82830",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Our csv files contains many categories we will not use, and splits the article into headline, short-text and body.\n",
    "We will create a file that outputs the labeled data with the entire article in one piece.\n",
    "\n",
    "We set the file we want to work with here, along with a couple of output parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54748941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_ID</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>article</th>\n",
       "      <th>kurz_text</th>\n",
       "      <th>haupt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Spahn kündigt digitalen Impfpass zum Sommer an</td>\n",
       "      <td>\\r\\nDie EU arbeitet an einem digitalen Impfzer...</td>\n",
       "      <td>\\r\\nNachdem die Bundesregierung Lockerungen fü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>»Durchhalteparolen helfen Familien nicht«</td>\n",
       "      <td>\\r\\nSchulen dicht, Kitas im Notbetrieb – Famil...</td>\n",
       "      <td>\\r\\nSPIEGEL: Frau Midyatli, Sie haben zwei Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Wen Sie in Rheinland-Pfalz wählen wollen</td>\n",
       "      <td>\\r\\nWer regiert künftig in Mainz? In Rheinland...</td>\n",
       "      <td>\\r\\nIn Rheinland-Pfalz gibt es sie noch, die s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Dieser »Witz« ist Rassismus aus Bequemlichkeit</td>\n",
       "      <td>\\r\\nDer Satiriker Helmut Schleich malt sein Ge...</td>\n",
       "      <td>\\r\\nSatire darf ziemlich viel. Vor allem darf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Union und SPD lehnen Hilfe für Italien bei Boo...</td>\n",
       "      <td>\\r\\nZuletzt erreichten wieder deutlich mehr Bo...</td>\n",
       "      <td>\\r\\nPolitiker der Union und SPD haben einem Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2228</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\nArmin Laschet wird die Union in den Bundes...</td>\n",
       "      <td>\\r\\nArmin Laschet ist Kanzlerkandidat der Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>2229</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Politiker empören sich nach Wahl von Max Otte ...</td>\n",
       "      <td>\\r\\nNach der Wahl Max Ottes zum neuen Vorsitze...</td>\n",
       "      <td>\\r\\nDer rechtsgerichtete Ökonom Max Otte ist n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>2230</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\nDie Konferenz zur Zukunft Europas ist gere...</td>\n",
       "      <td>\\r\\nDas monatelange Gezerre um die Ausgestaltu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2231</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Was vom G7-Treffen zu erwarten ist</td>\n",
       "      <td>\\r\\nLiebe Leserin, lieber Leser, guten Morgen,...</td>\n",
       "      <td>\\r\\nBoris Johnson darf wieder spielen – den Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2232</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Politik</td>\n",
       "      <td>Viele Menschen bei antiisraelischen Demonstrat...</td>\n",
       "      <td>\\r\\nIn Deutschland sind erneut Hunderte Mensch...</td>\n",
       "      <td>\\r\\nZahlreiche Demonstranten haben am Samstag ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2233 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Line_ID  day  month  year category  \\\n",
       "0           0    5      5  2021  Politik   \n",
       "1           1   25      1  2021  Politik   \n",
       "2           2   10      2  2021  Politik   \n",
       "3           3    3      4  2021  Politik   \n",
       "4           4    4      6  2021  Politik   \n",
       "...       ...  ...    ...   ...      ...   \n",
       "2228     2228   20      4  2021  Politik   \n",
       "2229     2229   31      5  2021  Politik   \n",
       "2230     2230    7      5  2021  Politik   \n",
       "2231     2231   10      6  2021  Politik   \n",
       "2232     2232   22      5  2021  Politik   \n",
       "\n",
       "                                                article  \\\n",
       "0        Spahn kündigt digitalen Impfpass zum Sommer an   \n",
       "1             »Durchhalteparolen helfen Familien nicht«   \n",
       "2              Wen Sie in Rheinland-Pfalz wählen wollen   \n",
       "3        Dieser »Witz« ist Rassismus aus Bequemlichkeit   \n",
       "4     Union und SPD lehnen Hilfe für Italien bei Boo...   \n",
       "...                                                 ...   \n",
       "2228                                       \\r\\n\\r\\n\\r\\n   \n",
       "2229  Politiker empören sich nach Wahl von Max Otte ...   \n",
       "2230                                       \\r\\n\\r\\n\\r\\n   \n",
       "2231                 Was vom G7-Treffen zu erwarten ist   \n",
       "2232  Viele Menschen bei antiisraelischen Demonstrat...   \n",
       "\n",
       "                                              kurz_text  \\\n",
       "0     \\r\\nDie EU arbeitet an einem digitalen Impfzer...   \n",
       "1     \\r\\nSchulen dicht, Kitas im Notbetrieb – Famil...   \n",
       "2     \\r\\nWer regiert künftig in Mainz? In Rheinland...   \n",
       "3     \\r\\nDer Satiriker Helmut Schleich malt sein Ge...   \n",
       "4     \\r\\nZuletzt erreichten wieder deutlich mehr Bo...   \n",
       "...                                                 ...   \n",
       "2228  \\r\\nArmin Laschet wird die Union in den Bundes...   \n",
       "2229  \\r\\nNach der Wahl Max Ottes zum neuen Vorsitze...   \n",
       "2230  \\r\\nDie Konferenz zur Zukunft Europas ist gere...   \n",
       "2231  \\r\\nLiebe Leserin, lieber Leser, guten Morgen,...   \n",
       "2232  \\r\\nIn Deutschland sind erneut Hunderte Mensch...   \n",
       "\n",
       "                                             haupt_text  \n",
       "0     \\r\\nNachdem die Bundesregierung Lockerungen fü...  \n",
       "1     \\r\\nSPIEGEL: Frau Midyatli, Sie haben zwei Sch...  \n",
       "2     \\r\\nIn Rheinland-Pfalz gibt es sie noch, die s...  \n",
       "3     \\r\\nSatire darf ziemlich viel. Vor allem darf ...  \n",
       "4     \\r\\nPolitiker der Union und SPD haben einem Au...  \n",
       "...                                                 ...  \n",
       "2228  \\r\\nArmin Laschet ist Kanzlerkandidat der Unio...  \n",
       "2229  \\r\\nDer rechtsgerichtete Ökonom Max Otte ist n...  \n",
       "2230  \\r\\nDas monatelange Gezerre um die Ausgestaltu...  \n",
       "2231  \\r\\nBoris Johnson darf wieder spielen – den Ga...  \n",
       "2232  \\r\\nZahlreiche Demonstranten haben am Samstag ...  \n",
       "\n",
       "[2233 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_ext = \".csv\"\n",
    "txt_ext = \".txt\"\n",
    "simple_in = \"leicht_nachricht\"\n",
    "simple_out = \"leichte_sprache\"\n",
    "norm_cult_in = \"Kultur_normal\"\n",
    "norm_cult_out = \"kultur_normal\"\n",
    "norm_sport_in = \"Sport_normal\"\n",
    "norm_sport_out = \"sport_normal\"\n",
    "norm_poli_in = \"Politik_normal\"\n",
    "norm_poli_out = \"politik_normal\"\n",
    "\n",
    "input_filename = norm_poli_in + csv_ext\n",
    "output_filename_csv = \"clean_\" + norm_poli_out + csv_ext\n",
    "metadata_output_filename = norm_poli_out + \"_meta\" + txt_ext\n",
    "metadata_string = \"\"\n",
    "\n",
    "df = pd.read_csv(input_filename)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5593760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "        ... \n",
      "2228    True\n",
      "2229    True\n",
      "2230    True\n",
      "2231    True\n",
      "2232    True\n",
      "Name: label, Length: 2233, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "cleanArray = []\n",
    "for index in df.loc[:,\"Line_ID\"]:\n",
    "    if index in [1285, 3781, 5648, 5663]:\n",
    "        #there are four articles without a body. We simply exclude those from our data for simplicity\n",
    "        pass\n",
    "    else:\n",
    "        #first we extract the article\n",
    "        article = df.loc[index,\"article\"]\n",
    "    \n",
    "        #next up the short text\n",
    "        short_text = df.loc[index,\"kurz_text\"]\n",
    "    \n",
    "        #and finally the main body of the article\n",
    "    \n",
    "        body = df.loc[index,\"haupt_text\"]\n",
    "        if type(body) is float:\n",
    "            print(index)\n",
    "            break\n",
    "    \n",
    "        #our resulting text contains some unicode symbols, namely \\xa0, that we dont want, so we replace it with\n",
    "        #a space. We also remove line breaks\n",
    "        \n",
    "        text = article + \" \" + short_text + body\n",
    "        text = text.replace(u'\\xa0', u' ')\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        text = text.replace(\"\\r\", \"\")\n",
    "    \n",
    "    \n",
    "        newEntry = [text, df.loc[index, \"category\"]]\n",
    "    \n",
    "    \n",
    "    cleanArray.append(newEntry)\n",
    "    \n",
    "    \n",
    "cleanDf_with_misc = pd.DataFrame(cleanArray, columns=[\"text\", \"label\"])\n",
    "#Our data contained articles with the category \"miscellaneous\", which we dont intend to use\n",
    "#We therefore exclude it from this file\n",
    "is_not_misc = cleanDf_with_misc[\"label\"]!=\"Vermischtes\"\n",
    "print(is_not_misc)\n",
    "cleanDf = cleanDf_with_misc[is_not_misc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08c41041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spahn kündigt digitalen Impfpass zum Sommer an...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>»Durchhalteparolen helfen Familien nicht« Schu...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wen Sie in Rheinland-Pfalz wählen wollen Wer r...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dieser »Witz« ist Rassismus aus Bequemlichkeit...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Union und SPD lehnen Hilfe für Italien bei Boo...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>Armin Laschet wird die Union in den Bundestag...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>Politiker empören sich nach Wahl von Max Otte ...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>Die Konferenz zur Zukunft Europas ist gerette...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>Was vom G7-Treffen zu erwarten ist Liebe Leser...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>Viele Menschen bei antiisraelischen Demonstrat...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label\n",
       "0     Spahn kündigt digitalen Impfpass zum Sommer an...  Politik\n",
       "1     »Durchhalteparolen helfen Familien nicht« Schu...  Politik\n",
       "2     Wen Sie in Rheinland-Pfalz wählen wollen Wer r...  Politik\n",
       "3     Dieser »Witz« ist Rassismus aus Bequemlichkeit...  Politik\n",
       "4     Union und SPD lehnen Hilfe für Italien bei Boo...  Politik\n",
       "...                                                 ...      ...\n",
       "2228   Armin Laschet wird die Union in den Bundestag...  Politik\n",
       "2229  Politiker empören sich nach Wahl von Max Otte ...  Politik\n",
       "2230   Die Konferenz zur Zukunft Europas ist gerette...  Politik\n",
       "2231  Was vom G7-Treffen zu erwarten ist Liebe Leser...  Politik\n",
       "2232  Viele Menschen bei antiisraelischen Demonstrat...  Politik\n",
       "\n",
       "[2233 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cleanDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aaa14412",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf.to_csv(output_filename_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aa854",
   "metadata": {},
   "source": [
    "### Now we have cleaned data, and we can do a little analysis for gathering metadata.\n",
    "We begin by counting how many articles we have total, and split by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "971ebd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_kultur = cleanDf[\"label\"] == \"Kultur\"\n",
    "kultur = cleanDf[is_kultur]\n",
    "is_nachrichten = cleanDf[\"label\"] == \"Nachrichten\"\n",
    "nachrichten = cleanDf[is_nachrichten]\n",
    "is_sport = cleanDf[\"label\"] == \"Sport\"\n",
    "sport = cleanDf[is_sport]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "516c836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles labelled \"culture\": 0\n",
      "Number of articles labelled \"news\": 0\n",
      "Number of articles labelled \"sport\": 0\n",
      "Total number of articles: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles labelled \\\"culture\\\": \" + str(len(kultur)))\n",
    "print(\"Number of articles labelled \\\"news\\\": \" + str(len(nachrichten)))\n",
    "print(\"Number of articles labelled \\\"sport\\\": \" + str(len(sport)))\n",
    "print(\"Total number of articles: \" + str(len(kultur) + len(nachrichten) + len(sport)))\n",
    "metadata_string += \"Number of articles labelled \\\"culture\\\": \" + str(len(kultur)) + \"\\n\"\n",
    "metadata_string += \"Number of articles labelled \\\"news\\\": \" + str(len(nachrichten)) + \"\\n\"\n",
    "metadata_string += \"Number of articles labelled \\\"sport\\\": \" + str(len(sport)) + \"\\n\"\n",
    "metadata_string += \"Total number of articles: \" + str(len(kultur) + len(nachrichten) + len(sport)) + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b6fe4d",
   "metadata": {},
   "source": [
    "Now we get a little more detailed. We determine the number of words and types in our entire collection, the average length of an article, and we compute the average flesch reading ease of our texts, using the textstat package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c986dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1cbb965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 200674\n",
      "average flesch reading ease of our articles: 33.060528437080166\n",
      "average length of an article (words): 89.86744290192566\n"
     ]
    }
   ],
   "source": [
    "textstat.set_lang(\"de\") #we're dealing with german text\n",
    "\n",
    "\n",
    "input_string = \"\"\n",
    "aggregate_reading_ease = 0\n",
    "aggregate_article_length = 0\n",
    "for text in cleanDf[\"text\"] :\n",
    "    input_string += text + \" \"\n",
    "    aggregate_reading_ease += textstat.flesch_reading_ease(text)\n",
    "    aggregate_article_length += textstat.lexicon_count(text)\n",
    "    \n",
    "#for some things, we want all the articles together, for some global metrics\n",
    "\n",
    "lexicon = textstat.lexicon_count(input_string, removepunct=True)\n",
    "print(\"Number of unique words:\", lexicon)\n",
    "metadata_string += \"Number of unique words:\" + str(lexicon) + \"\\n\"\n",
    "    \n",
    "average_reading_ease = aggregate_reading_ease / len(cleanDf[\"text\"])\n",
    "print(\"average flesch reading ease of our articles:\", average_reading_ease)\n",
    "metadata_string += \"average flesch reading ease of our articles:\" + str(average_reading_ease) + \"\\n\"\n",
    "\n",
    "average_article_length = aggregate_article_length / len(cleanDf[\"text\"])\n",
    "print(\"average length of an article (words):\", average_article_length)\n",
    "metadata_string += \"average length of an article (words):\" + str(average_article_length) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccbc7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = input_string.lower()\n",
    "\n",
    "#rewrite input to all lower case, to avoid counting the same type twice due to capitalization\n",
    "input_words = input_string.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "822fbd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = 0\n",
    "alreadySeen = []\n",
    "#initialize counters for types and tokens\n",
    "#initialize a list to keep track of the types already counted\n",
    "for word in input_words:\n",
    "    if word[:-1] == \".\":\n",
    "        word = word[:-1]\n",
    "    if word in alreadySeen:\n",
    "        pass\n",
    "    else:\n",
    "        alreadySeen.append(word)\n",
    "        types = types + 1\n",
    "        \n",
    "#go through each word, counting the token up each time, and counting the types each time a new one occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "009f127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of types in the collection: 33140\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of types in the collection:\", types)\n",
    "metadata_string += \"Number of types in the collection:\" + str(types) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "014c9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_article_length = 0\n",
    "for text in kultur[\"text\"] :\n",
    "    aggregate_article_length += textstat.lexicon_count(text)\n",
    "    \n",
    "if len(kultur[\"text\"]) > 0:\n",
    "    average_article_length = aggregate_article_length / len(kultur[\"text\"])\n",
    "    print(\"culture: average length of an article (words):\", average_article_length)\n",
    "    metadata_string += \"culture: average length of an article (words):\" + str(average_article_length) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1e2bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_article_length = 0\n",
    "for text in sport[\"text\"] :\n",
    "    aggregate_article_length += textstat.lexicon_count(text)\n",
    "    \n",
    "if len(sport[\"text\"]) > 0 :\n",
    "    average_article_length = aggregate_article_length / len(sport[\"text\"])\n",
    "    print(\"sport: average length of an article (words):\", average_article_length)\n",
    "    metadata_string += \"sport: average length of an article (words):\" + str(average_article_length) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a83c623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_article_length = 0\n",
    "for text in nachrichten[\"text\"] :\n",
    "    aggregate_article_length += textstat.lexicon_count(text)\n",
    "    \n",
    "if len(nachrichten[\"text\"]) > 0:   \n",
    "    average_article_length = aggregate_article_length / len(nachrichten[\"text\"])\n",
    "    print(\"politics: average length of an article (words):\", average_article_length)\n",
    "    metadata_string += \"politics: average length of an article (words):\" + str(average_article_length) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9f01ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote metadata into a file\n"
     ]
    }
   ],
   "source": [
    "with open(metadata_output_filename, \"a\") as meta_file:\n",
    "    meta_file.write(metadata_string)\n",
    "    print(\"wrote metadata into a file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b635903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
